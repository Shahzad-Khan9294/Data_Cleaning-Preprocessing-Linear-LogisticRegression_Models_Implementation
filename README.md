# Code Notebooks Overview
## The notebooks contain practical implementations of key machine learning algorithms including:
- Linear Regression
- Logistic Regression
- K-Nearest Neighbors (KNN)
- Support Vector Machines (SVM)
- Naive Bayes
### They demonstrate how these models handle various types of datasets and tasks, such as:
- Numerical, Categorical, and Ordinal Data
- Binary and Multi-Class Classification
- Ensemble Techniques

## 1. Data Preparation
- Data Cleaning: Handling missing values, removing duplicates, correcting errors.
-  Data Wrangling: Transforming data into the desired format for analysis.
-  Outlier Detection and Removal: Identifying and addressing anomalies to improve model performance.
-  Balancing Data: Techniques such as oversampling, undersampling, or synthetic data generation to handle class imbalance.

## 2. Feature Engineering

- Feature Creation: Generating new features from existing data for better model learning.
- Feature Relational Understanding: Analyzing correlations and interactions between feature columns.
- Binning: Converting continuous features into categorical bins for certain algorithms.
  ### Dimensionality Reduction:
  - PCA (Principal Component Analysis) – reduces feature space while preserving variance.
  - t-SNE – visualizing high-dimensional data in lower dimensions.
- Normalization and Standardization: Scaling features for algorithms sensitive to feature magnitude.

## 3. Exploratory Data Analysis (EDA)
- Plotting and Visualization: Histograms, boxplots, scatterplots, correlation heatmaps to understand data distribution.
- Hypothesis Testing: Statistical tests to validate assumptions about the data.

## 4. Model Implementation
- Step-by-step application of the algorithms: Linear, Logistic, KNN, SVM, and Naive Bayes.
- Handling classification tasks, both binary and multi-class.
- Demonstrating ensemble techniques to improve predictive performance.

## 5. Model Evaluation
- Score Calculations: Accuracy, F1-score, precision, recall, ROC-AUC, etc.
- Understanding when and why to apply different models based on data type and feature relationships.
- Interpretation of outputs and insights for practical use.

<div style="display: flex; flex-direction: row;">
    <img src="https://github.com/user-attachments/assets/00c8926a-c223-4140-9748-b4d3c1d3dcfe" width="220"/>
    <img src="https://github.com/user-attachments/assets/652bba7a-7549-4465-ac30-8abb325d4db2" width="220"/>
    <img src="https://github.com/user-attachments/assets/2812ceab-ef26-4cba-8beb-b87a225fbe8a" width="220" />
    <img src="https://github.com/user-attachments/assets/81e99fcf-9b2a-41e4-9e6f-65665a018cda" width="220" />
    <img src="https://github.com/user-attachments/assets/99293b8f-c3a7-4ccb-98aa-75fd6eaa7f46" width="220" />
    <img src="https://github.com/user-attachments/assets/c9d63adb-881d-4e16-9883-44c631e7e55d" width="220" />
</div>






